{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: hit_and_run_rule\n",
      "Inning: 13, Pitch Count: 100, Opponent Batter: R, Runner on First: True, Runner on Second: False, Runner on Third: False, Outs: 0, Close Play: False, Challenges Left: 2, Pitcher: R, Score Difference: 0, Runs Allowed Last 2 Innings: 0, Current Batter Avg: 0.229, Opponent Batter Tendency: right, Home Score: 54, Away Score: 0\n",
      "Action: Change pitcher\n"
     ]
    }
   ],
   "source": [
    "%run knowledge.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar la efectividad del modelo\n",
    "\n",
    "### 1. Validación Cruzada: \n",
    "Utiliza técnicas de validación cruzada para evaluar el rendimiento del modelo en diferentes subconjuntos de datos. Esto ayuda a garantizar que el modelo generalice bien a datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1.]\n",
      "Mean accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Evaluar el modelo utilizando validación cruzada\n",
    "scores = cross_val_score(model, X_train, y_train, cv=2)\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean accuracy: {scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matriz de Confusión\n",
    "Una matriz de confusión te permite ver cuántas predicciones fueron correctas y cuántas fueron incorrectas, desglosadas por cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Datos de prueba (ejemplo)\n",
    "X_test = np.array([[100, 1], [85, 0], [120, 1], [95, 0]])\n",
    "y_test = np.array([1, 0, 1, 0])\n",
    "\n",
    "# Predicciones del modelo\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Métricas de Rendimiento\n",
    "Utiliza métricas como precisión, recall y F1-score para evaluar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluación en Simulaciones\n",
    "Simula partidos completos utilizando el modelo para tomar decisiones y compara los resultados con partidos históricos o con decisiones tomadas por managers humanos.\n",
    "\n",
    "Comparación de Resultados: Comparar las decisiones del modelo con las decisiones históricas y evaluar el impacto en el resultado del partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions taken: ['Change pitcher', 'No change', 'Change pitcher', 'No change']\n"
     ]
    }
   ],
   "source": [
    "def simulate_game(manager, game_states):\n",
    "    results = []\n",
    "    for state in game_states:\n",
    "        action = manager.evaluate_rules_and_model(state)\n",
    "        results.append(action)\n",
    "    return results\n",
    "\n",
    "# Ejemplo de estados del juego\n",
    "game_states = [\n",
    "    {'pitch_count': 105, 'opponent_batter': 1},\n",
    "    {'pitch_count': 85, 'opponent_batter': 0},\n",
    "    {'pitch_count': 120, 'opponent_batter': 1},\n",
    "    {'pitch_count': 95, 'opponent_batter': 0}\n",
    "]\n",
    "\n",
    "# Simular el juego\n",
    "actions = simulate_game(hybrid_manager, game_states)\n",
    "print(f\"Actions taken: {actions}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
